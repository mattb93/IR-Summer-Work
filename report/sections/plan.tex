\chapter{Plan}\label{ch:plan}
\foxComment{You should update this section as time advances}

Our work on this project will happen in two phases. In the first phase, we will attempt to create an initial prototype working with a small set of sample data. This phase will be accomplished mainly in our own external environment so that we can experiment more freely with the technologies to gain a better understanding of how they work and interact together. 

Phase two of the project will involve taking the work done in phase one and expanding it out to the other small sets of data provided to us, and eventually to larger data sets. We will explore other potential techniques as we deem them necessary. This phase will also include a definition and implementation of an evaluation approach. Phase one is small enough that we feel a subjective evaluation is sufficient, but as we expand it will become essential to have a more concrete, quantitative measure of effectiveness.

Please see Table \ref{table:plan} for a weekly breakdown of work.

\rowcolors{2}{gray!25}{white}
\begin{table}
\caption{Weekly breakdown of work to be done.}\label{table:plan}
\begin{tabularx}{155mm}{|>{\setlength\hsize{.2\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{.3\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{1.5\hsize}\setlength\linewidth{\hsize}}X|}
	\rowcolor{gray!50}
%\multicolumn{3}{|c|}{Classification of the criticel point $(0,0)$ of $x'=Ax,|\mathbf{A}|\not=0$.}\\
\hline
\centering Weeks & \centering End Date & Tasks \\
\hline

Week 1
&
22 Jan.
&
Understanding the classification task\\
\hline

Week 2
&
29 Jan.
&
\begin{itemize}
\item Understanding the classification task
\item Read about \href{https://canvas.vt.edu/courses/21271/files/folder/2015/Tutorials?preview=390175}{Hadoop streaming using Python}
\end{itemize}\\
\hline

Week 3
&
5 Feb.
&
Start online tutorials about Hadoop and Apache Spark. \cite{pythonSparkTutorial}\cite{solrTeamTutorial}\\
\hline

Week 4
&
12 Feb.
&
Continue online tutorials about Hadoop and Apache Spark. \cite{hbaseShellTutorial}\\
\hline

Week 5
&
19 Feb.
&
\textbf{Phase 1 will include only tweets small data set:}
\begin{itemize}
\item Understanding the classification task
\item Read about Hadoop streaming using Python
\end{itemize}\\
\hline

Week 6
&
26 Feb.
&
\begin{itemize}
\item Prepare training data using Solr
\item Build classifier using Apache Spark
\end{itemize}\\
\hline

Week 7
&
4 March
&
\begin{itemize}
\item Build classifier using Apache Spark
\item Get output data format from Solr team
\end{itemize}\\
\hline

Week 8
&
11 March
&
Optimize classifier performance\\
\hline
\end{tabularx}
\end{table}
\newpage
\begin{tabularx}{155mm}{|>{\setlength\hsize{.2\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{.3\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{1.5\hsize}\setlength\linewidth{\hsize}}X|}
\hline
% \multicolumn{3}{|c|}{Classification of the criticel point $(0,0)$ of $x'=Ax,|\mathbf{A}|\not=0$.}\\
% \hline
Weeks & End Date & Tasks \\
\hline
Week 9
&
18 March
&
\textbf{Phase 2 will include tweets and webpages:} \

\textbf{Once Spark on the cluster is updated to version 1.5 we will do the following:}

\begin{itemize}
\item Run our methodology to classify the tweets on the cluster.
\item Apply the Frequent Pattern methodology on the cleaned webpages provided by Collection Management team.
\item Develop HBase interface through which the classifier prediction output will be saved on HBase.
\end{itemize}\\
\hline

Week 10
&
25 March
&
Design an evaluation approach to test and evaluate our methodology. \\
\hline

Week 11
&
1 April
&
Discuss with GRAs and Solr team to finalize HBase schema. \\
\hline

Week 12
&
8 April
&
Move functioning prototype over to newly updated Hadoop cluster. Train multiple classifiers and pick the best model per collection. \\
\hline

Week 13
&
15 April
&
More research on hyper-parameter optimization. Check the feasibility of integrating hyper-parameters optimization library \cite{bergstra2013hyperopt} output with Spark. \\
\hline

Week 14
&
22 April
&
Search for known approaches to select the most representative data samples for each collection. Then check whether training a classifier using these data samples will enhance the performance or not. \\
\hline

Week 15
&
29 April
&
Final evaluations and modifications to the system. \\
\hline

\end{tabularx}